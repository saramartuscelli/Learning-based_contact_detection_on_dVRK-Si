{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uidb8rsUPR_w"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loading"
      ],
      "metadata": {
        "id": "4jca-AINqpbW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df1 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/THESIS/data_oct9/1.csv')\n",
        "df2 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/THESIS/data_oct9/1.csv')\n",
        "df3 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/THESIS/data_oct9/3.csv')\n",
        "df4 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/THESIS/data_oct9/4.csv')\n",
        "df5 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/THESIS/data_oct9/5.csv')\n",
        "df6 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/THESIS/data_oct9/6.csv')\n",
        "df7 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/THESIS/data_oct9/7.csv')\n",
        "df8 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/THESIS/data_oct9/8.csv')\n",
        "df9 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/THESIS/data_oct9/9.csv')\n",
        "df10 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/THESIS/data_oct9/10.csv')\n",
        "\n",
        "df_validation = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/THESIS/data_oct9/validation.csv')\n",
        "df_test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/THESIS/data_oct9/test.csv')"
      ],
      "metadata": {
        "id": "gyc1yVRlqmVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data preparation\n"
      ],
      "metadata": {
        "id": "ksSifjiVhUFt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# outliers removal\n",
        "\n",
        "df4 = df4.drop(range(3500, 5500))\n",
        "df6 = df6.drop(range(47000, len(df6)))\n",
        "df9 = df9[(df9['contacts'])==0]"
      ],
      "metadata": {
        "id": "VyWZ9d5qvsZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Splitting\n"
      ],
      "metadata": {
        "id": "XiokYLFQP0Sz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.concat([df1, df2, df3, df4, df5, df6, df7, df8, df9, df10], ignore_index=True)\n",
        "\n",
        "print(\"Training test:\", df_train.shape)\n",
        "print(\"Validation test:\", df_validation.shape)\n",
        "print(\"Test test:\", df_test.shape)"
      ],
      "metadata": {
        "id": "cN7d8UCKP0Sz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Visualization"
      ],
      "metadata": {
        "id": "CzdXQF5eGG_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.plot(subplots=True, figsize=(50, 50))"
      ],
      "metadata": {
        "id": "3JDq8fZ4P_pN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_validation.plot(subplots=True, figsize=(50, 50))"
      ],
      "metadata": {
        "id": "ktPW6L14QMzy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.plot(subplots=True, figsize=(50, 50))"
      ],
      "metadata": {
        "id": "-M1hfgeDQMrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Inputs (X and y)"
      ],
      "metadata": {
        "id": "biuFeCqmQWAb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = df_train.drop(['timestamps_sensor', 'contacts'], axis=1)\n",
        "y_train = df_train['contacts']\n",
        "print(\"Training: \", X_train.shape)\n",
        "\n",
        "X_validation = df_validation.drop(['timestamps_sensor', 'contacts'], axis=1)\n",
        "y_validation = df_validation['contacts']\n",
        "print(\"Validation: \", X_validation.shape)\n",
        "\n",
        "X_test = df_test.drop(['timestamps_sensor', 'contacts'], axis=1)\n",
        "y_test = df_test['contacts']\n",
        "print(\"Test: \", X_test.shape)"
      ],
      "metadata": {
        "id": "bmGHwBdrQVjq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Scaling"
      ],
      "metadata": {
        "id": "vpOYRqqIQat6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale data between -1 and 1\n",
        "import numpy as np\n",
        "\n",
        "max_train = X_train.max()\n",
        "min_train = X_train.min()\n",
        "\n",
        "print(\"max_train = \", list(max_train.values))\n",
        "print(\"min_train = \", list(min_train.values), \"\\n\")\n",
        "\n",
        "X_train_scaled = (X_train - min_train) / (max_train - min_train) * 2 - 1\n",
        "X_validation_scaled = (X_validation - min_train) / (max_train - min_train) * 2 - 1\n",
        "X_test_scaled = (X_test - min_train) / (max_train - min_train) * 2 - 1\n",
        "\n",
        "print(\"Training: \", X_train_scaled.shape)\n",
        "print(\"Training: \", X_validation_scaled.shape)\n",
        "print(\"Test: \", X_test_scaled.shape)"
      ],
      "metadata": {
        "id": "DrEMygnlQdYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sliding Windows\n"
      ],
      "metadata": {
        "id": "0HHkU8NJtJBN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Generator (Train e Validation)"
      ],
      "metadata": {
        "id": "I4G8mNvHDaLH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def window_generator(data, labels, window_size=100, step=10, strategy='center'):\n",
        "    n_samples = len(data)\n",
        "    for i in range(0, n_samples - window_size + 1, step):\n",
        "        window = data[i:i+window_size]\n",
        "        window_labels = labels[i:i+window_size]\n",
        "\n",
        "        # label definition with different strategies\n",
        "        if strategy == 'center':\n",
        "            label = window_labels[window_size // 2]\n",
        "        elif strategy == 'max':\n",
        "            label = np.max(window_labels)\n",
        "        elif strategy == 'mode':\n",
        "            label = np.bincount(window_labels).argmax()\n",
        "        elif strategy == 'probability':\n",
        "            label = np.mean(window_labels)\n",
        "        else:\n",
        "            raise ValueError(f\"Invalid strategy: {strategy}\")\n",
        "\n",
        "        yield window.astype(np.float32), np.float32(label)    # yield returns one window at time -> should not saturate RAM"
      ],
      "metadata": {
        "id": "vOLN_dPa2Lcx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "window_size = 100\n",
        "step = 10\n",
        "strategy = 'probability'\n",
        "batch_size = 64\n",
        "\n",
        "train_dim = (len(X_train_scaled) - window_size + 1) // step\n",
        "validation_dim = (len(X_validation_scaled) - window_size + 1) // step\n",
        "\n",
        "train_windows = tf.data.Dataset.from_generator(\n",
        "    lambda: window_generator(X_train_scaled, y_train, window_size, step, strategy),\n",
        "    output_signature=(\n",
        "        tf.TensorSpec(shape=(window_size, X_train_scaled.shape[1]), dtype=tf.float32),  # X\n",
        "        tf.TensorSpec(shape=(), dtype=tf.float32)                                       # y\n",
        "    )\n",
        ")\n",
        "\n",
        "train_windows = train_windows.shuffle(buffer_size=train_dim, reshuffle_each_iteration=True)\n",
        "train_windows = train_windows.batch(batch_size).repeat().prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "\n",
        "validation_windows = tf.data.Dataset.from_generator(\n",
        "    lambda: window_generator(X_validation_scaled, y_validation, window_size, step, strategy),\n",
        "    output_signature=(\n",
        "        tf.TensorSpec(shape=(window_size, X_validation_scaled.shape[1]), dtype=tf.float32),  # X\n",
        "        tf.TensorSpec(shape=(), dtype=tf.float32)                                            # y\n",
        "    )\n",
        ")\n",
        "\n",
        "# no shuffle nel validation set!\n",
        "validation_windows = validation_windows.batch(batch_size).repeat().prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "P_EsUD2R2j7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Static Dataset (Test)"
      ],
      "metadata": {
        "id": "ZUqBKFwgDUOA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def create_windows(data, labels, window_size=100, step=10, strategy='center'):\n",
        "\n",
        "    X, y, idx = [], [], []\n",
        "    n_samples, n_features = data.shape\n",
        "\n",
        "    for i in range(0, n_samples - window_size + 1, step):\n",
        "        window = data[i:i+window_size]\n",
        "        window_labels = labels[i:i+window_size]\n",
        "        index = i + window_size // 2\n",
        "\n",
        "        if strategy == 'center':\n",
        "            label = window_labels[window_size // 2]\n",
        "        elif strategy == 'max':\n",
        "            label = np.max(window_labels)\n",
        "        elif strategy == 'mode':\n",
        "            label = np.bincount(window_labels).argmax()\n",
        "        elif strategy == 'probability':\n",
        "            label = np.mean(window_labels)\n",
        "        else:\n",
        "            raise ValueError(f\"Invalid strategy: {strategy}\")\n",
        "\n",
        "        X.append(window)\n",
        "        y.append(label)\n",
        "        idx.append(index)\n",
        "\n",
        "    return (\n",
        "        np.array(X, dtype=np.float32),\n",
        "        np.array(y, dtype=np.float32),\n",
        "        np.array(idx, dtype=np.int64)\n",
        "    )"
      ],
      "metadata": {
        "id": "svjW9TMTDThX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_windows, y_test_windows, index_test = create_windows(X_test_scaled.values, y_test.values,\n",
        "                                                            window_size=window_size,\n",
        "                                                            step=step,\n",
        "                                                            strategy=strategy)\n",
        "\n",
        "print(\"Test test:\", X_test_windows.shape, y_test_windows.shape)"
      ],
      "metadata": {
        "id": "Kz1m2vLcQz2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Kinematic + Accelerometer Model Prediction"
      ],
      "metadata": {
        "id": "ISPNMN0kTYl6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_ka = tf.keras.models.load_model('/content/drive/MyDrive/Colab Notebooks/THESIS/Saved Models oct12/best_model_1.keras')"
      ],
      "metadata": {
        "id": "lxDPoqQBTYMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "thr = 0.5\n",
        "\n",
        "y_pred_prob_ka = model_ka.predict(X_test_windows_ka).flatten()\n",
        "y_pred_ka = (y_pred_prob_ka > thr).astype(int)\n",
        "y_test = (y_test_windows_ka > thr).astype(int)"
      ],
      "metadata": {
        "id": "IP6ALL54UL4y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Kinematic-only Model Predictions"
      ],
      "metadata": {
        "id": "f8CF9uQuUU2C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = df_train.drop(['timestamps_sensor', 'acc_x', 'acc_y', 'acc_z', 'contacts'], axis=1)\n",
        "y_train = df_train['contacts']\n",
        "print(\"Training: \", X_train.shape)\n",
        "\n",
        "X_validation = df_validation.drop(['timestamps_sensor', 'acc_x', 'acc_y', 'acc_z', 'contacts'], axis=1)\n",
        "y_validation = df_validation['contacts']\n",
        "print(\"Validation: \", X_validation.shape)\n",
        "\n",
        "X_test = df_test.drop(['timestamps_sensor', 'acc_x', 'acc_y', 'acc_z', 'contacts'], axis=1)\n",
        "y_test = df_test['contacts']\n",
        "print(\"Test: \", X_test.shape)"
      ],
      "metadata": {
        "id": "dP2gSppUUfqK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale data between -1 and 1\n",
        "import numpy as np\n",
        "\n",
        "max_train = X_train.max()\n",
        "min_train = X_train.min()\n",
        "\n",
        "print(\"max_train = \", list(max_train.values))\n",
        "print(\"min_train = \", list(min_train.values), \"\\n\")\n",
        "\n",
        "X_train_scaled = (X_train - min_train) / (max_train - min_train) * 2 - 1\n",
        "X_validation_scaled = (X_validation - min_train) / (max_train - min_train) * 2 - 1\n",
        "X_test_scaled = (X_test - min_train) / (max_train - min_train) * 2 - 1\n",
        "\n",
        "print(\"Training: \", X_train_scaled.shape)\n",
        "print(\"Training: \", X_validation_scaled.shape)\n",
        "print(\"Test: \", X_test_scaled.shape)"
      ],
      "metadata": {
        "id": "dhZgqfqVUgfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_windows, y_test_windows, index_test = create_windows(X_test_scaled.values, y_test.values,\n",
        "                                                            window_size=window_size,\n",
        "                                                            step=step,\n",
        "                                                            strategy=strategy)\n",
        "\n",
        "print(\"Test test:\", X_test_windows.shape, y_test_windows.shape)"
      ],
      "metadata": {
        "id": "ssjsU4EtUyS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_k = tf.keras.models.load_model('/content/drive/MyDrive/Colab Notebooks/THESIS/Ablation Study/best_model_k2.keras')"
      ],
      "metadata": {
        "id": "c54b7cf5ULxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "thr = 0.5\n",
        "\n",
        "y_pred_prob_k = model_k.predict(X_test_windows).flatten()\n",
        "y_pred_k = (y_pred_prob_k > thr).astype(int)\n",
        "y_test = (y_test_windows > thr).astype(int)"
      ],
      "metadata": {
        "id": "-FeD9QCFU0yi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STATISTICAL TESTS"
      ],
      "metadata": {
        "id": "me5BiQrvVKB6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "def block_indices(n, B):\n",
        "    nb = n // B\n",
        "    idx = [(i*B, (i+1)*B) for i in range(nb)]\n",
        "    return idx\n",
        "\n",
        "def metric_per_block(y, s_full, s_abl, B, metric_fn):\n",
        "    idxs = block_indices(len(y), B)\n",
        "    m_full, m_abl = [], []\n",
        "    for a,b in idxs:\n",
        "        m_full.append(metric_fn(y[a:b], s_full[a:b]))\n",
        "        m_abl.append(metric_fn(y[a:b], s_abl[a:b]))\n",
        "    return np.array(m_full), np.array(m_abl)\n",
        "\n",
        "\n",
        "from sklearn.metrics import accuracy_score, recall_score, mean_squared_error\n",
        "\n",
        "def metric(y, pred):\n",
        "    # return mean_squared_error(y, pred)\n",
        "    # return accuracy_score(y, pred)\n",
        "    # return precision_score(y, pred)\n",
        "    return recall_score(y, pred)\n",
        "\n",
        "\n",
        "B = 250\n",
        "mF, mA = metric_per_block(y_test, y_pred_ka, y_pred_k, B, metric)\n",
        "print('Full:', mF.mean(), 'Abl:', mA.mean())\n",
        "\n",
        "d = mF - mA\n",
        "\n",
        "stat, p_shapiro = stats.shapiro(d)\n",
        "print(\"p_shapiro =\", p_shapiro)\n",
        "\n",
        "\n",
        "# Test appaiato robusto\n",
        "def paired_test(d, alternative='greater'):\n",
        "\n",
        "    if p_shapiro > 0.05:\n",
        "        w, p = stats.wilcoxon(d, alternative=alternative, zero_method='wilcox')\n",
        "    else:\n",
        "        w, p = stats.ttest_rel(mF, mA, alternative=alternative)\n",
        "\n",
        "    return {'p': p, 'mean_diff': d.mean(), 'std_diff': d.std(ddof=1)}\n",
        "\n",
        "\n",
        "res = paired_test(d)\n",
        "print(res)"
      ],
      "metadata": {
        "id": "LzYXr4dpU3wR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}